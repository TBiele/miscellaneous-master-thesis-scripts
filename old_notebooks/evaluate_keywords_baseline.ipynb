{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd53638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89261465",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_MODEL_NAME = \"2021-12-20T17-54-59_MULT_DistilBERT\"\n",
    "TRAINED_MODEL_DIR = f\"../models/{TRAINED_MODEL_NAME}\"\n",
    "\n",
    "# Load data\n",
    "df_true = pd.read_csv(f\"{TRAINED_MODEL_DIR}/labeled_messages_ground_truth.csv\")\n",
    "df_predicted = pd.read_csv(\n",
    "    f\"{TRAINED_MODEL_DIR}/labeled_messages_keywords_baseline_prediction.csv\"\n",
    ")\n",
    "\n",
    "# Load mappings between labels and label ids\n",
    "id2label = pickle.load(open(f\"{TRAINED_MODEL_DIR}/id2label.p\", \"rb\"))\n",
    "label2id = pickle.load(open(f\"{TRAINED_MODEL_DIR}/label2id.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f6ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if label mapping corresponds to the table columns\n",
    "df_only_label_columns = df_true.drop([\"message_hash\", \"content\"], axis=1)\n",
    "misconception_columns = list(df_only_label_columns.columns)\n",
    "if len(misconception_columns) != len(list(label2id.keys())):\n",
    "    print(\n",
    "        \"Warning: The evaluation will not work as expected because the baseline uses a \"\n",
    "        \"different number of labels than the model it is supposed to be compared with\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6562ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build boolean label vectors\n",
    "true_labels_lists = df_only_label_columns.values.tolist()\n",
    "true_labels_flat = [np.array(sublist) for sublist in true_labels_lists]\n",
    "true_bools = [item == 1 for item in true_labels_flat]\n",
    "\n",
    "predicted_labels_lists = df_predicted.drop(\n",
    "    [\"message_hash\", \"content\"], axis=1\n",
    ").values.tolist()\n",
    "predicted_labels_flat = [np.array(sublist) for sublist in predicted_labels_lists]\n",
    "predicted_bools = [item == 1 for item in predicted_labels_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8370b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print and save classification report\n",
    "print(\"F1-Score: \", f1_score(true_bools, predicted_bools, average=\"micro\"))\n",
    "print(\"Accuracy: \", accuracy_score(true_bools, predicted_bools), \"\\n\")\n",
    "clf_report = classification_report(\n",
    "    true_bools, predicted_bools, target_names=misconception_columns\n",
    ")\n",
    "# Save report\n",
    "if not os.path.isdir(f\"{TRAINED_MODEL_DIR}/results/\"):\n",
    "    os.makedirs(f\"{TRAINED_MODEL_DIR}/results/\")\n",
    "with open(f\"{TRAINED_MODEL_DIR}/results/keywords_baseline_report.txt\", \"w\") as f:\n",
    "    f.write(clf_report)\n",
    "\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d86d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting indices of where boolean one hot vector true_bools is True so we can use \n",
    "# id2label to gather label names\n",
    "true_label_idxs, pred_label_idxs = [], []\n",
    "for vals in true_bools:\n",
    "    true_label_idxs.append(np.where(vals)[0].flatten().tolist())\n",
    "for vals in predicted_bools:\n",
    "    pred_label_idxs.append(np.where(vals)[0].flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2fee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering vectors of label names using id2label\n",
    "true_label_texts, pred_label_texts = [], []\n",
    "for vals in true_label_idxs:\n",
    "    if vals:\n",
    "        true_label_texts.append([id2label[val] for val in vals])\n",
    "    else:\n",
    "        true_label_texts.append(vals)\n",
    "\n",
    "for vals in pred_label_idxs:\n",
    "    if vals:\n",
    "        pred_label_texts.append([id2label[val] for val in vals])\n",
    "    else:\n",
    "        pred_label_texts.append(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding input ids to comment text\n",
    "comment_texts = [message[0] for message in df_true[[\"content\"]].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ad40ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting lists to df\n",
    "comparisons_df = pd.DataFrame(\n",
    "    {\n",
    "        \"comment_text\": comment_texts,\n",
    "        \"true_labels\": true_label_texts,\n",
    "        \"pred_labels\": pred_label_texts,\n",
    "    }\n",
    ")\n",
    "comparisons_df.to_csv(\n",
    "    f\"{TRAINED_MODEL_DIR}/results/keywords_baseline_true_predicted_comparison.csv\"\n",
    ")\n",
    "comparisons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c0b9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
